# -*- coding: utf-8 -*-
"""Respaldo_Arbol_COCONUT_prediccion_final

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dGvPr2QO-k2ZkATT0tXlEPSxHIr9OO25

# Arboles de Decisión

Es un modelo predicción y aprendisaje automatico basado en una seria de posbiles resultados ocurridos por la toma de decisiones.
Los árboles de decisión se construyen a partir de un conjunto de datos de entrenamiento que contiene variables predictoras (características) y una variable objetivo (clase o valor a predecir)

El algoritmo comienza seleccionando la característica que mejor divide los datos en grupos más puros o homogéneos con respecto a la variable objetivo. Esto se hace midiendo la impureza de los grupos, por ejemplo, usando el índice de Gini o la entropía.

Una vez seleccionada la mejor característica de división, el algoritmo crea un nodo raíz y divide los datos en subgrupos según los valores de esa característica.

El proceso se repite recursivamente para cada subgrupo, seleccionando la siguiente característica que mejor divide esos datos, hasta que se llega a nodos terminales (hojas) que representan las predicciones finales.

Para hacer una predicción con el árbol, se recorre el árbol desde el nodo raíz hasta una hoja, siguiendo las condiciones en cada nodo interno hasta llegar a la clase o valor predicho.

Los árboles de decisión son fáciles de interpretar y explicar, pero pueden volverse muy complejos si se crean árboles demasiado profundos.

Este modelo puede ser representado por un árbol que contiene:
1. Un conjunto de condicionales (Nodos sin hojas)
2. Un conjunto de clases (Hojas)
3. Un conjunto de características (x)
"""

# Instalar librerías necesarias (Solo ejecutar si no están instaladas)
from IPython.utils import io
import tqdm.notebook

total = 100
with tqdm.notebook.tqdm(total=total) as pbar:
    with io.capture_output() as captured:
        # Instalar rdkit
        !pip -q install rdkit.pypi==2021.9.4
        pbar.update(20)
        # Instalar Pillow
        !pip -q install Pillow
        pbar.update(40)
        # Instalar molplotly
        !pip install molplotly
        pbar.update(60)
        # Instalar jupyter-dash
        !pip install jupyter-dash
        pbar.update(80)
        # Instalar el diseño de aplicación dash
        !pip install dash-bootstrap-components
        pbar.update(100)

# Importar librerías
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import silhouette_score
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

"""# Set de Datos

Partimnos de un set de datos que contiene 206 compuestos geroprotectores obtenidos de geroprotectors.org y 199 compuestos con etiqueta de toxicos obtenidos de ChEMBL por medio de API.
Para el modelo de Machine Learning se usara de la siguiente manera, los datos fueron binados y ordenados en datos de prueba y entrenamiento.

0= compuestos NO geroprotectores (prueba)

1= compuestos geroprotectores con pruebas experimentales (test)
"""

# Leer bases de datos
datos = "/content/drive/MyDrive/INGER/ETAPA 2024/Version Final/0. Data Set/Concatenadas.csv"
datos = pd.read_csv(datos)

# Agregar una columna de índices
datos['Index'] = datos.index

# Información del dataset
datos.info()

# Separar las las columnas de las variables predictorias (X) de la columna que contiene la variable a predecir (Y)
#X = datos.iloc[:, 1:20]
#y = datos.iloc[:, 44]

# Separar las las columnas de las variables predictorias (X) de la columna que contiene la variable a predecir (Y)
# PODEMOS UTILIZAR UNICAMENTE COLUMNAS (DESCRIPTORES) DE INTERES PARA ENTRENAR EL MODELO Y NO CAER EN SOBREAJUSTE.
columnas_interes = [1, 3, 5, 6, 7, 8, 20]
X = datos.iloc[:, columnas_interes]
y = datos.iloc[:, 44]

# Separar datos en conjuntos de entrenamiento y prueba

#indicamos que se partan los datos en un 80% para la entrenamiento y 20% para prueba,
#el valor de random_state=42 nos indica que el algoritmo utilizará los mismos datos de entrenamiento y prueba lo que nos dara reproducibilidad

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)

"""#Creacion del modelo de Arbol de decision

Árbol de Decisión Binario: Un árbol de decisión binario es una estructura de datos utilizada en la toma de decisiones y en el aprendizaje automático. Se caracteriza por su forma jerárquica, donde cada nodo representa una condición o decisión relacionada con una variable, y cada rama indica el resultado de esa decisión, dividiendo así el espacio de posibles resultados en dos partes.
Los árboles de decisión son fundamentales en la creación de modelos predictivos, donde se busca agrupar observaciones con características similares para predecir una variable de respuesta.
"""

# Creación del modelo de Árbol de Decisión Binario
arbol = DecisionTreeClassifier(criterion='entropy', max_depth=None, random_state=42)

# Entrenar el modelo
arbol_geros = arbol.fit(X_train, y_train)

# Predecir la respuesta en base a las etiquetas para todos los datos
y_pred_all = arbol_geros.predict(X)

"""# Resultados"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Generar y visualizar la matriz de confusión
conf_matrix = confusion_matrix(y_test, arbol_geros.predict(X_test))
class_names = y_test.unique()
disp = ConfusionMatrixDisplay(conf_matrix, display_labels=class_names)
disp.plot(cmap=plt.cm.Blues)
plt.show()

tp = 22
fp = 18
fn = 13
tn = 28

"""### Accurucy (precisión)

Es el porcentaje de predicciones correctas sobre el total de predicciones realizadas.

![accuracy.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAOsAAAAxCAYAAAA7r16cAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAk2SURBVHhe7ZzPa9tIFMf3X8nfIcjZ5LC3mh5EYAMLNYHiy5pCcWBxDsWUjVko7iEiYFQo6FAUCMrBIDAoEBwI6BAQBAQ5CAL+H96+NzP6acmxN24T2e/wAVsezWgm+s689+ZNftvZ2QGGYV4/LFaGqQksVoapCSxWhqkJLFaGqQksVoapCSxWhqkJLFaGqQksVmYFdOidmmCOFvC5DT1rCtPrIh44oz6098rqXYz216C8rYQhdP8xwI3bmljQ3Y3vb4ExzjyH1cvVXSdYrMwKGDB9DMD50oHWYQta332YzUJwT/Azfu9ZPkS+BU0s2/jkQjibgfdFE/dqbw6gfxHALJqCsV9WN7LXgEbJ9e5lCNGNCT1q83AAbjiD2a0ln+HDENz7CNxPVLYB5nUEEbYbXnZBi+vY06E/DsD/1oZmIuL6wWJlVgBXL7effj+bCrE6H+PfO+BcO9Clzx8dFGv2NwLFjkKaXQ0y11K6lw4YpdddsN7G37vgkFhvjLTMKa6YZ/KzQXVchPK5juREIThzCs9SP1iszPJ8sMH93kq/z4l1B4YXDvToc6lYB+A9FoSWoUqsQ9eFQfK9RKz4XM7Z7+IzibW70wY7wDIhfo5X0u0RaxfMiQODZHZjGKRErAklYtWO6FoE09NmvqyiSqx5SsSaQYoVP7+3IcBVPEJLQJjDWyPWY1f4AcGPzKzKME+KFcUSBhAERAiB74L5oTFfVrFWsSK68KnJn0VzeFvE2ncj7DQOUGBDq+R3ZktZQqyxLzlPG8zrWMiS8CGCMPOdcL9K8zZlebFS9NryseyDC/3RVoi1Dy4OYvSAnZ4FYL8vK8NsJc8S6zzrXlkF+yb46CdHD/4WiPUTmsC3Jjr5cnUNztvl5Zjt49WJVQNzXBAroo/kFtPGi5VMYP9bU4pWmcLtknIpDWh/NsAeT8E9N8H41Er3uxTamy4MvzvgTRywRkPoxBvlu004OGxBB+83v3bFfh3Vp4v9tD4YtPmtglyNfdpz68FwZEL/vQbNoyGYp/lNd9HOyAJn4oJN977JhPILNN5j/ecuTMe2qKcloohY759yDzFGF/Xnrx8sqHcjObZEgoFPosF3IvQp4cAF41D+LpIifNo+wRUtWD4RYbFYVXLDTSDfwyjIJzkcGuDeKXft3gfrOHuvDgbet+FiJRPYB1MIhD7TH2eBKbw/ADfAP9Ad/uH+xhf51JMb1BddVUaDDjr90WOIg9yHzmEX7Dsa+CkY1AYOuHevBpzC7uKeHpYJ8R5qO50de+fo40R0DVf7G3xxUJBk7iSTSRINHApB9UZTCB8jnOl19SwxOgzGtFmP/tFpD8viM1C999Q+vSB+0s4swvbFS9CSvhBdo76MOPC2DpZbWbeXxWJVJrBc4dJAU7kprIN5Sy+vB8N4b+tEijWayE1wGbrP3o8vPYkVJwBLzcrClKF6ErFKKItlzpRRptbszgIdzSMbZ9bwypDPqyLYs+vYXNJgeEVt4cSQyWKRJlKaaSP2AkmckZfu7cXCH2dWiLcWriz4jE9kxBx8m6K/RD7/skzB/KO8ro2nIoOJkSwUa2ICx9cWmcKxcHLZKWQu6uoPoKEpQmLBlTkRJrKnz5mRotwKYqXUsuRaArV9kEsvm69D+T84waSb7jI1Tpq7MU25kmYmouY3n/135peyQKzK7I3yM78w/cpMYRFsqBIOoYRBK1vp7ynrESuK7t0A7Gu1JXCHpvI9tZ+tQ6W/Fdoqg8RJ/Zue0cRCGTKxe/AyyL8DUxfK/oarUi3WggkcU2kKv6BYyyKOzX89KeQr9FnVajhfx/Ji3dkdylQ5GhM0saneYuCsFLQc4kDUcuStAYaJqRTr4KpgAsdUmcJvTfDpujp1kd6jQ+9ERnZ7YxJ6fEIihY5A9TMr9fPF2pK5oVn/GUnr6IA9saGD5q3wj2d+JlFcoh8PkshzjHz+APzbELx/879V8fTxriJpxHsxW3ZcTUWgq3BP6dRP2W//t6+FZ53Dgl6ujAdW5uBA69QtlC3WvzqlYtXe0UZyCO5x2ZZEVVRYU2KIwDtJU8o0FHeAfqxYhfZxJaPgDQo6Xu3opbNu83UN4kCQ+r6zG6/KKLSjtFxiBl900msCJdZcMEkldwuxYh98ORnEQS8KgiXBjV38PUA/trjCqUATZcSsY/Cfx6YeV9OgsVfy3gkLpdCeoAfGBJ9JxUrW11e1PVcYV6Lz2QY/SmMvjdEUongHIelTA/TP+O6jJdZe09ZeQay44ogXOiU4zwjhq6e2UFIoM8T+EN+vw+CStmbwD0R7bzcBPqydi5hqf5kwpQF/kPtkPqWUfSlsp3y0cDBUHVTmzgMTX76kzckQhhN8ETLPQv609zXTzhENKP4W+qoOfM4TNVmgHx6cp+a6fuLIsveybID+qJ09XpUgBf86AkubelzNAOcpV2ouIWIA3pUpJ4Q19lVQkfjR+oErdrxwUH8QsXBkJ6aFfVmdBQGmZ6CSG1r71UnbMqlhkX+mZrY/m7LzYmZd1Z+LkxfiiDSBs2ipSVRWtsjLB5YSNva42ipiHYKHEzdF681Lcmvw2hr7KiiMawdFKhanY+xDvDio/rR/4ApOZZOJqQ5i3RjQtP/h4wqPfhd9XyWw9KupWAEEJS/w6z2utqRYaUFAMzMstr3uvmbGtbHfARNdtrlnT/qjJiY6OCAmJhbrLyTr+7aEb139kr0wT4oVxVKL42pLiFW5UNMgmm973X0V44rm7S25ZDhxP5aMcbY/++jCJRMTi/WXInxf8Uf3wTkppiq+IpYQa3VS/QseVztxcm2QuKIHFFj2GsU9RB3F9tAXrRDr2vpaGNfu5XSxWJF0YjJZrEwJzxLrPOteWQVLHVdb0gwW3xugF+Mi6+5rYVy1N/p83GTOUlCptzgJ+CxWZo5XJ9b/e1xtFbGW8JPFWoY2cvNbioSamKqThFaHxVp3Nu64WoVYqZ+F9vL1rruvso+5cR0bhf+UgmVcfCaKNKMv6xfa01HoAYuV+dkst7L+DNYblFmGl+vrarBYmXJe7LhaRQbTz6QmR/NYrAxTE1isDFMTWKwMUxNYrAxTE1isDFMTWKwMUxNYrAxTE1isDFMTWKwMUxNYrAxTE1isDFMTWKwMUxNYrAxTE1isDFMLduA/53T4z//klJ0AAAAASUVORK5CYII=)

donde:

TP: Verdaderos positivos

TN: Verdaderos negativos

FP: Falsos positivos

FN: Falsos negativos
"""

# Mostrar la precisión del modelo en el conjunto de prueba
from sklearn.metrics import accuracy_score
accuracy = (tp + tn) / (tp + fp + fn + tn)
#accuracy = accuracy_score(y_test, arbol_geros.predict(X_test))
print("Accuracy:", accuracy)

"""### Especificidad

 Es la capacidad del modelo para identificar correctamente las muestras negativas.

 También se conoce como tasa de verdaderos negativos.

 ![especificidad.png](data:image/png;base64,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)
"""

from sklearn.metrics import confusion_matrix
# Calculate the specificity score
specificity = tn / (tn + fp)
print("Specificity:", specificity)



# Crear un nuevo dataframe con todos los resultados
resultados_arbol = datos.copy()
resultados_arbol['Prediction'] = y_pred_all

resultados_arbol

# Visualizar el árbol de decisión
fig = plt.figure(figsize=(50, 40))
ax = fig.add_subplot(111)
class_names = list(map(str, y.unique()))
tree.plot_tree(arbol_geros, feature_names=list(X.columns), class_names=class_names, filled=True, ax=ax)
plt.show()

# Guardar los resultados en un archivo CSV
#resultados_arbol.to_csv('resultados_arbol.csv', index=False)



"""#Predicciones

De los datos obtenidos en coconut data base.

COCONUT es una plataforma dedicada a recopilar y proporcionar información sobre propiedades, aplicaciones, beneficios para la salud de productos naturales. Esta base de datos cuenta con mas de 400 mil compuestos.
"""

# Cargar la base de datos COCONUT
coconut_data = pd.read_csv("/content/drive/MyDrive/INGER/ETAPA 2024/DATA /COCONUT_DesMol.csv")

coconut_data.dropna(inplace=True)

coconut_data.info()

# Preprocesar los datos de COCONUT
# Asegúrate de que coconut_data tenga las mismas columnas que usaste para entrenar el modelo
coconut_features = coconut_data.iloc[:, [5, 8, 10, 11, 12, 13, 25]]

# Utilizar el modelo para hacer predicciones
coconut_predictions = arbol_geros.predict(coconut_features)

# Añadir las predicciones a tu DataFrame de COCONUT
coconut_data['Prediccion'] = coconut_predictions

coconut_data

# Guardar los resultados en un archivo CSV
#coconut_data.to_csv('coconut_arbol_prediccion.csv', index=False)

# Analizar los resultados
# Contar cuántos compuestos se predicen como activos o inactivos
print(coconut_data['Prediccion'].value_counts())

# Filtrar los compuestos predichos como activos
compuestos_activos = coconut_data[coconut_data['Prediccion'] == 1]

# Mostrar los primeros compuestos predichos como activos
compuestos_activos.head(10)



"""# Curva ROC del modelo

La curva ROC (Receiver Operating Characteristic) es una herramienta gráfica para evaluar el rendimiento de un modelo de clasificación binaria. Muestra la relación entre la tasa de verdaderos positivos (sensibilidad) y la tasa de falsos positivos (1 - especificidad) a medida que varía el umbral de decisión del clasificador.
"""

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Obtener las probabilidades de predicción para la clase positiva
y_pred_proba = arbol_geros.predict_proba(X_test)[:, 1]

# Calcular la curva ROC
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)

# Calcular el área bajo la curva ROC
roc_auc = auc(fpr, tpr)

# Graficar la curva ROC
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Imprimir el AUC
print('AUC: %.2f' % roc_auc)